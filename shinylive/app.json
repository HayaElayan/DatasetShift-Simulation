[{"name":"app.R","content":"require(shiny)\nrequire(ggplot2)\nrequire(scales)\nrequire(boot)\nrequire(magrittr)\nrequire(dplyr)\nrequire(MASS)\nrequire(Matrix)\nrequire(ROCR)\nrequire(MLmetrics)\nrequire(Metrics)\nrequire(matrixcalc)\nrequire(DescTools)\nrequire(predtools)\nrequire(tidyr)\nrequire(waiter)\nrequire(shinyjs)\nrequire(bslib)\nrequire(future)\nrequire(promises)\nrequire(shinyBS)\n\n\nplan(sequential) \ninvisible(future(NULL))\n# Create the matrix\n\nCORR_MATRIX <- matrix(c(\n  1,   0.4, 0.4, 0,   0.4,\n  0.4, 1,   0.5, 0,   0.3,\n  0.4, 0.5, 1,   0,   0.6,\n  0,   0,   0,   1,   0.4,\n  0.4, 0.3, 0.6, 0.4, 1\n), nrow = 5, byrow = TRUE)\n\npredictors_names <- c(\"X1\", \"X2\", \"X3\", \"X4\", \"X5\")\ncolnames(CORR_MATRIX) <-predictors_names\nbinary_predictors <- c('X3','X4', 'X5')\nlambda_hyperparam_values <- c(seq(0, 1, by = 0.1), 0.05, 0.08, 0.15, 0.25, 0.03)\nfolds_num=4\n\nmeans_target <- c(0,0, 0,0,0)\nbinary_prev_target <- c(0.3, 0.4, 0.1)\nB_coeffcients_target <-  c(-3.1, 0.5, 0.3, 0.7, 0.8, 0.2)\n#iteration<-1\n\n\ngenerate_development <- function( N_samples, target_split, binary_predictors,\n                                  means_target, means_delta, corr_matrix, variances_delta,\n                                  binary_prev_target, binary_prev_delta, predictors_names, \n                                  B_coeffcients_target, B_coeffcients_delta, iteration){\n  \n  source_n <- round(100000*(1-target_split)) \n  target_n <- round(100000*target_split)\n  \n  source <- generate_covariates_source(source_n, binary_predictors,\n                                       means_target, means_delta, corr_matrix, variances_delta,\n                                       binary_prev_target, binary_prev_delta, predictors_names, iteration)\n  \n  target <- generate_covariates_target(target_n, binary_predictors, means_target, corr_matrix,\n                                       binary_prev_target, predictors_names, iteration, \"target\")\n  \n  \n  source_with_outcome <- generate_outcome_source(source, B_coeffcients_target,  B_coeffcients_delta,iteration)\n  target_with_outcome <- generate_outcome_target(target, B_coeffcients_target, iteration, \"target\")\n  source_with_outcome$isSource <- 1\n  target_with_outcome$isSource <- 0\n  \n  source_n <- round(N_samples*(1-target_split)) \n  target_n <- round(N_samples*target_split)\n  \n  source_with_outcome <- source_with_outcome[sample(nrow(source_with_outcome), size = source_n, replace = FALSE), ]\n  target_with_outcome<- target_with_outcome[sample(nrow(target_with_outcome), size = target_n, replace = FALSE), ]\n  \n  full_data <- list(source=source_with_outcome, target=target_with_outcome)\n  return(full_data)\n}\n\n\ngenerate_covariates_source<-function(N, binary_predictors, means, means_delta, corr_mat,\n                                     variances_delta , binary_prev, binary_prev_delta, colnames, iteration){\n  set.seed(123454*iteration)\n  \n  corr_mat <- covarinace_matrix(corr_mat, variances_delta)\n  means <- (means+means_delta)\n  binary_prev <- binary_prev+binary_prev_delta\n  \n  \n  data <- as.data.frame(mvrnorm(n=N,\n                                mu=means,\n                                Sigma=corr_mat ))\n  colnames(data) <- colnames\n  \n  to_binary_variables <- mapply(to_binray, data[, binary_predictors], binary_prev, iteration ) #apply binary conversion function\n  data[, binary_predictors ] <- as.data.frame(to_binary_variables) #pass result to dataframe\n  \n  return(data)\n}\n\n\ngenerate_covariates_target<-function(N, binary_predictors, means, corr_mat,\n                                     binary_prev, colnames, iteration, dataset_type){\n  if(dataset_type==\"target\"){\n    set.seed(123455*iteration) #target\n  }else{\n    set.seed(123456*iteration) #validation\n  }\n  \n  data <- as.data.frame(mvrnorm(n=N,\n                                mu=means,\n                                Sigma=corr_mat ))\n  colnames(data) <- colnames\n  \n  to_binary_variables <- mapply(to_binray, data[, binary_predictors], binary_prev, iteration ) #apply binary conversion function\n  data[, binary_predictors ] <- as.data.frame(to_binary_variables) #pass result to dataframe\n  \n  return(data)\n}\n\n\ngenerate_covariates_target<-function(N, binary_predictors, means, corr_mat,\n                                     binary_prev, colnames, iteration, dataset_type){\n  if(dataset_type==\"target\"){\n    set.seed(12345*iteration) #target\n  }else{\n    set.seed(12346*iteration) #validation\n  }\n  \n  data <- as.data.frame(mvrnorm(n=N,\n                                mu=means,\n                                Sigma=corr_mat ))\n  colnames(data) <- colnames\n  \n  to_binary_variables <- mapply(to_binray, data[, binary_predictors], binary_prev, iteration ) #apply binary conversion function\n  data[, binary_predictors ] <- as.data.frame(to_binary_variables) #pass result to dataframe\n  \n  return(data)\n}\n\ngenerate_outcome_source <- function(covariates, coeffs_target, coeffs_delta, iteration ){\n  set.seed(12344*iteration)\n  \n  mat <- covariates  %>% data.matrix()\n  \n  coeffs <- coeffs_target + coeffs_delta \n  \n  alpha <- coeffs[1]\n  \n  xb <- alpha + (mat%*%coeffs[-1])\n  p <-  1/(1 + exp(-xb))\n  y <- rbinom(n = nrow(covariates), size = 1, prob = p)\n  #print(table(y)/nrow(covariates))\n  \n  drop_cols <- which(coeffs[-1] == 0)\n  #print(drop_cols)\n  if(length(drop_cols) > 0){\n    covariates<-covariates %>% dplyr::select(-all_of(drop_cols))\n  }\n  covariates$Y <- y\n  return(covariates)\n}\n\n\ngenerate_outcome_target <- function(covariates, coeffs_target, iteration, dataset_type){\n  if(dataset_type==\"target\"){\n    set.seed(12345*iteration) #target\n  }else{\n    set.seed(12346*iteration) #validation\n  }\n  \n  mat <- covariates  %>% data.matrix()\n  \n  coeffs <- coeffs_target\n  \n  alpha <- coeffs[1]\n  \n  xb <- alpha + (mat%*%coeffs[-1])\n  p <-  1/(1 + exp(-xb))\n  y <- rbinom(n = nrow(covariates), size = 1, prob = p)\n  \n  drop_cols <- which(coeffs[-1] == 0)\n  \n  if(length(drop_cols) > 0){\n    covariates<-covariates %>% dplyr::select(-all_of(drop_cols))\n  }\n  covariates$Y <- y\n  return(covariates)\n}\n\n\ncovarinace_matrix <- function(corr_mat, delta_v){\n  diag(corr_mat) <- diag(corr_mat)+delta_v\n  std <- sqrt(diag(corr_mat))\n  cm <- corr_mat * outer(std, std)\n  return(cm)\n}\n\n\nbrier_score <- function(pred, obs) mean((pred - obs)^2, na.rm = TRUE)\n\n\n\nto_binray <- function(variable, prevalence, iteration){\n  set.seed(13567*iteration)\n  # Determine threshold value\n  threshold <- quantile(variable, 1 - prevalence)\n  # Convert continuous variable to binary\n  binary_variable <- ifelse(variable >= threshold, 1, 0)\n  return(binary_variable)\n}\n\n\ngenerate_validation <- function( N_samples=10000, binary_predictors,\n                                 means_target, corr_matrix,\n                                 binary_prev_target, predictors_names, \n                                 B_coeffcients_target){\n  iteration <- 1\n  target <- generate_covariates_target(N_samples , binary_predictors, means_target, corr_matrix,\n                                       binary_prev_target, predictors_names, iteration, \"validation\")\n  \n  target_with_outcome <- generate_outcome_target(target, B_coeffcients_target, iteration, \"validation\")\n  target_with_outcome$isSource <- 0\n  \n  return(target_with_outcome)\n}\n\ndevelop_cpm <- function(dev){\n  model <- glm(Y ~ X1 + X2 + X3 + X4 + X5, data = dev, family = binomial)\n  return(model)\n}\n\n\nintercept_calibration <- function(source, target) {\n  target <- target %>% dplyr::select(-c(isSource))\n  source <- source %>% dplyr::select(-c(isSource))\n  train_data <- rbind(source, target)\n  \n  source_model <- glm(Y ~ X1 + X2 + X3 + X4 + X5, data=train_data, family = 'binomial', x=TRUE, y=TRUE)\n  \n  target$lp <- predict(source_model, newdata=target) #get Lp of source model on target data\n  calibrated_model <- glm(Y~offset(lp), data=target, family='binomial',x=T, y=T)#update intercept only\n  \n  \n  return(list(calibrated_model=calibrated_model, source_model=source_model))\n  \n}\n\nlogistic_calibration <-function(source, target) {\n  \n  target <- target %>% dplyr::select(-c(isSource))\n  source <- source %>% dplyr::select(-c(isSource))\n  train_data <- rbind(source, target)\n  \n  source_model <- glm(Y ~ X1 + X2 + X3 + X4 + X5, data=train_data, family = 'binomial', x=TRUE, y=TRUE)\n  \n  target$lp <- predict(source_model, newdata=target) #get Lp of source model on target data\n  calibrated_model <- glm(Y~lp, data=target, family='binomial',x=T, y=T)#update all model's coeff\n  \n  return(list(calibrated_model=calibrated_model, source_model=source_model))\n} \n\n\n\npropensity_weighting_with_lambda<- function(source, target){\n  temp <- rbind(source, target)\n  \n  membership_model <- glm(isSource~X1+X2+X3+X4+X5, data=temp, family = 'binomial')\n  \n  \n  score <- predict(membership_model,type=\"response\", newdata = source) #predict p(isSource=1|X)\n  \n  propensity_weight <-  (1 - score)/ score #p(p(isSource=0|X)/ p(isSource=1|X))\n  #print(propensity_weight)\n  \n  propensity_weight <- propensity_weight*(nrow(source)/ nrow(target))\n  \n  propensity_weight[propensity_weight >= 1]= 1\n  source$propensity_weight <- propensity_weight\n  target$propensity_weight <- 1\n  \n  lambda <- find_lambda(source, target)\n  print(lambda)\n  weights_adjusted <- c(source$propensity_weight*lambda,target$propensity_weight)\n  return(weights_adjusted)\n}\n\n\nfind_lambda <- function(source, target){\n  hyperparam_values <- c(seq(0, 1, by = 0.1), 0.05, 0.08, 0.15, 0.25, 0.03)\n  mse_results <- numeric(length(hyperparam_values))\n  \n  for (i in seq_along(hyperparam_values)) {\n    lambda <- hyperparam_values[i]\n    \n    \n    folds <- custom_cv(source, target) \n    mse_values <- numeric(length(folds))\n    \n    for (j in seq_along(folds)) {\n      train_source_indices <- folds[[j]]$train_source\n      train_target_indices <- folds[[j]]$train_target\n      test_indices <- folds[[j]]$test\n      \n      train_source_data <- source[train_source_indices, ] \n      train_target_data <- target[train_target_indices, ] \n      test_data <- target[test_indices, ] \n      \n      source_target_weights <- propensity_weighting_x(train_source_data, train_target_data, lambda)\n      \n      result <- weighted_logistic_regression_x(train_source_data, train_target_data, test_data, weight = source_target_weights)\n      mse_values[j] <- calculate_mse(true_labels = test_data$Y, pred_probs = result)\n      \n    }\n    \n    mse_results[i] <- mean(mse_values)\n  }\n  \n  \n  optimal_param <- hyperparam_values[which.min(mse_results)]\n  return(optimal_param)\n}\n\n\n\npropensity_weighting_x<- function(source, target, lambda){\n  temp <- rbind(source, target)\n  \n  membership_model <- glm(isSource~X1+X2+X3+X4+X5, data=temp, family = 'binomial')\n  \n  score <- predict(membership_model,type=\"response\", newdata = source) #predict p(isSource=1|X)\n  \n  \n  propensity_weight <-  (1 - score)/ score #p(p(isSource=0|X)/ p(isSource=1|X))\n  \n  propensity_weight <- propensity_weight*(nrow(source)/ nrow(target))\n  \n  propensity_weight[propensity_weight >= 1]= 1\n  source$propensity_weight <- propensity_weight\n  target$propensity_weight <- 1\n  \n  weights <- c(source$propensity_weight*lambda,target$propensity_weight )\n  \n  return(weights)\n  \n}\n\n\n# Define custom cross-validation function\ncustom_cv <- function(source, target) {\n  indices_source <- sample(rep(1:4, length.out = nrow(source)))\n  indices_target <- sample(rep(1:4, length.out = nrow(target)))\n  \n  folds_list <- lapply(1:4, function(i) {\n    train_source_indices <- which(indices_source != i)\n    train_target_indices <- which(indices_target != i)\n    test_indices <- which(indices_target == i)\n    list(train_source = train_source_indices, train_target= train_target_indices, test = test_indices)\n  })\n  return(folds_list)\n}\n\n\n# Define function to calculate mean squared error\ncalculate_mse <- function(true_labels, pred_probs) {\n  mse <- MLmetrics::MSE(y_pred = pred_probs, y_true = true_labels)\n  return(mse)\n}\n\nweighted_logistic_regression_x <- function(source, target, test_data, weight) {\n  train_data <- rbind(source, target)\n  \n  model <- glm(Y~X1+X2+X3+X4+X5+isSource, data = train_data, weights = weight, family = binomial)\n  \n  pred_probs <- predict(model, newdata = test_data, type = \"response\")\n  \n  return( pred_probs)\n  \n}\n\nweighted_LR <- function(source, target, ps_weights) {\n  train_data <- rbind(source, target)\n  \n  model <- glm(Y~X1+X2+X3+X4+X5+isSource, data = train_data, weights = ps_weights, family = binomial)\n  #print(summary(model))\n  return( model)\n  \n}\n\n\n\n\n# Function to simulate and model data\nsimulate_data <-\n  function(N_SAMPLES = 1000,  target_split = 0.5, X0_b_delta = 0, \n           X1_m_delta = 0, X1_v_delta = 0,  X1_b_delta = 0,  \n           X2_m_delta = 0, X2_v_delta = 0, X2_b_delta = 0,\n           X3_p_delta = 0, X3_b_delta = 0, \n           X4_p_delta = 0, X4_b_delta = 0,\n           X5_p_delta = 0,  X5_b_delta = 0, cpm_method) {\n    \n    variances_delta <- c(X1_v_delta, X2_v_delta, 0, 0, 0)#input\n    means_delta <- c(X1_m_delta, X2_m_delta, 0, 0, 0) #input\n    binary_prev_delta <- c(X3_p_delta, X4_p_delta, X5_p_delta)#input\n    B_coeffcients_delta <-\n      c(X0_b_delta, X1_b_delta,   X2_b_delta,  X3_b_delta,  X4_b_delta,  X5_b_delta)#input\n    val_results <- list()\n    cal_plots <- list()\n    test <- c()\n    \n    for(iteration in 1:50){\n      source_target <-\n        generate_development(\n          N_SAMPLES,\n          target_split,\n          binary_predictors,\n          means_target,\n          means_delta,\n          CORR_MATRIX,\n          variances_delta,\n          binary_prev_target,\n          binary_prev_delta,\n          predictors_names,\n          B_coeffcients_target,\n          B_coeffcients_delta,\n          iteration\n        )\n      dev <- rbind(source_target$source, source_target$target)\n      if(iteration == 1){\n        test <-\n          generate_validation(\n            10000,\n            binary_predictors,\n            means_target,\n            CORR_MATRIX,\n            binary_prev_target,\n            predictors_names,\n            B_coeffcients_target\n          )\n      }\n      print(cpm_method)\n      if(cpm_method == \"Full-data Logistic Regression\"){\n        # Fit model\n        model <- develop_cpm(dev)\n        all_results <- CPM_validation_results(model, test)\n        val_results[[iteration]] <- all_results$val_results\n        cal_plots[[iteration]] <- all_results$cal_plot\n      }\n      \n      if(cpm_method == \"Target-dataset only logistic regression\"){\n        # Fit model\n        model <- develop_cpm(source_target$target)\n        all_results <- CPM_validation_results(model, test)\n        val_results[[iteration]] <- all_results$val_results\n        cal_plots[[iteration]] <- all_results$cal_plot\n      }\n      \n      if(cpm_method == \"Ancillary-dataset only logistic regression\"){\n        # Fit model\n        model <- develop_cpm(source_target$source)\n        all_results <- CPM_validation_results(model, test)\n        val_results[[iteration]] <- all_results$val_results\n        cal_plots[[iteration]] <- all_results$cal_plot\n      }\n      \n      if(cpm_method == \"Memebership-based Weighting\"){\n        # Fit model\n        weights <- propensity_weighting_with_lambda(source_target$source, source_target$target)\n        model <- weighted_LR(source_target$source, source_target$target, weights)\n        all_results <- proposed_model_validation_results(model, test)\n        val_results[[iteration]] <- all_results$val_results\n        cal_plots[[iteration]] <- all_results$cal_plot\n      }\n      \n      if(cpm_method == \"Intercept Recalibration on all data\"){\n        # Fit model\n        model <- intercept_calibration(source_target$source, source_target$target)\n        all_results <- calibrated_model_validation_results(model, \"intercept_only\", test)\n        val_results[[iteration]] <- all_results$val_results\n        cal_plots[[iteration]] <- all_results$cal_plot\n      }\n      \n      if(cpm_method == \"Logistic Recalibration on all data\"){\n        # Fit model\n        model <- logistic_calibration(source_target$source, source_target$target)\n        all_results <- calibrated_model_validation_results(model, \"logistic\", test)\n        val_results[[iteration]] <- all_results$val_results\n        cal_plots[[iteration]] <- all_results$cal_plot\n      }\n    }\n    # Shifted test data\n    return(list(\n      dev = dev,\n      train = source_target$source,\n      target = source_target$target,\n      val_results = val_results,\n      cal_plots = cal_plots)\n    )\n  }\n\n\nsimulate_noshift <-\n  function(N_SAMPLES = 1000,  target_split = 0.5, cpm_method) {\n    variances_delta <- c(0, 0, 0, 0, 0)#input\n    means_delta <- c(0, 0, 0, 0, 0) #input\n    binary_prev_delta <- c(0, 0, 0)\n    B_coeffcients_delta <-\n      c(0, 0, 0, 0, 0, 0)#input\n    val_results_noshift <- list()\n    cal_plots_noshift <- list()\n    \n    for(iteration in 1:50){\n      source_target <-\n        generate_development(\n          N_SAMPLES,\n          target_split,\n          binary_predictors,\n          means_target,\n          means_delta,\n          CORR_MATRIX,\n          variances_delta,\n          binary_prev_target,\n          binary_prev_delta,\n          predictors_names,\n          B_coeffcients_target,\n          B_coeffcients_delta,\n          iteration\n        )\n      dev <- rbind(source_target$source, source_target$target)\n      if(iteration == 1){\n        test <-\n          generate_validation(\n            10000,\n            binary_predictors,\n            means_target,\n            CORR_MATRIX,\n            binary_prev_target,\n            predictors_names,\n            B_coeffcients_target\n          )\n      }\n      \n      \n      print(cpm_method)\n      if(cpm_method == \"Full-data Logistic Regression\"){\n        # Fit model\n        model <- develop_cpm(dev)\n        all_results <- CPM_validation_results(model, test)\n        val_results_noshift[[iteration]] <- all_results$val_results\n        cal_plots_noshift[[iteration]] <- all_results$cal_plot\n      }\n      \n      if(cpm_method == \"Target-dataset only logistic regression\"){\n        # Fit model\n        model <- develop_cpm(source_target$target)\n        all_results <- CPM_validation_results(model, test)\n        val_results_noshift[[iteration]] <- all_results$val_results\n        cal_plots_noshift[[iteration]] <- all_results$cal_plot\n      }\n      \n      if(cpm_method == \"Ancillary-dataset only logistic regression\"){\n        # Fit model\n        model <- develop_cpm(source_target$source)\n        all_results <- CPM_validation_results(model, test)\n        val_results_noshift[[iteration]] <- all_results$val_results\n        cal_plots_noshift[[iteration]] <- all_results$cal_plot\n      }\n      \n      if(cpm_method == \"Memebership-based Weighting\"){\n        # Fit model\n        weights <- propensity_weighting_with_lambda(source_target$source, source_target$target)\n        model <- weighted_LR(source_target$source, source_target$target, weights)\n        all_results <- proposed_model_validation_results(model, test)\n        val_results_noshift[[iteration]] <- all_results$val_results\n        cal_plots_noshift[[iteration]] <- all_results$cal_plot\n      }\n      \n      if(cpm_method == \"Intercept Recalibration on all data\"){\n        # Fit model\n        model <- intercept_calibration(source_target$source, source_target$target)\n        all_results <- calibrated_model_validation_results(model, \"intercept_only\", test)\n        val_results_noshift[[iteration]] <- all_results$val_results\n        cal_plots_noshift[[iteration]] <- all_results$cal_plot\n      }\n      \n      if(cpm_method == \"Logistic Recalibration on all data\"){\n        # Fit model\n        model <- logistic_calibration(source_target$source, source_target$target)\n        all_results <- calibrated_model_validation_results(model, \"logistic\", test)\n        val_results_noshift[[iteration]] <- all_results$val_results\n        cal_plots_noshift[[iteration]] <- all_results$cal_plot\n      }\n    }\n    # Shifted test data\n    return(list(\n      dev = dev,\n      train = source_target$source,\n      target = source_target$target,\n      val_results_noshift = val_results_noshift,\n      cal_plots_noshift = cal_plots_noshift)\n    )\n  }\n\n#bootstrap validation results\nCPM_validation_results <- function(model, validation){\n  if(all(is.na(model))){\n    val_results <- matrix(nrow = 1,ncol = 4)\n    colnames(val_results) <- c('AUC', 'CITL', 'CSLOPE', 'BrierScore') #'MER' = mean estimated risk\n    \n    val_results[1,1] <- NA\n    val_results[1,2] <- NA\n    val_results[1,3] <- NA\n    val_results[1,4] <- NA\n    \n    Sm.full <- rep(NA, 100)\n    return(list(val_results = as.data.frame(val_results), cal_plot = list(sm = Sm.full)) )\n  }else{\n    val_results <- matrix(nrow = 1,ncol = 4)\n    colnames(val_results) <- c('AUC', 'CITL', 'CSLOPE', 'BrierScore') #'MER' = mean estimated risk\n    \n    \n    pr_val <- predict(model, type=\"response\", newdata = validation) # predict probabilities \n    lp_val <- predict(model, type=\"link\", newdata = validation ) # predict lp type=link\n    \n\n    #val_cstat_model <- #roc(Y ~ pr_val,data=validation)\n    #val_results[1,1] <- val_cstat_model$auc\n    \n    pred <- prediction(pr_val, validation$Y)\n    perf <- performance(pred, \"tpr\", \"fpr\")    \n    auc <- performance(pred, \"auc\")@y.values[[1]]\n    val_results[1,1] <- auc\n    \n    val_results[1,4] <- brier_score(validation$Y, pred=pr_val) \n    tryCatch(\n      { \n        val_citl_model <- glm(Y ~ offset(lp_val),family=binomial, data=validation)\n        val_results[1,2] <- summary(val_citl_model)$coefficients[1,1]\n        \n        val_cslope_model <- glm(Y ~ lp_val,family=binomial(link='logit'), data=validation)\n        val_results[1,3] <- summary(val_cslope_model)$coefficients[2,1]\n        \n        \n        Sm       <- lowess(pr_val, validation$Y, iter = 0)\n        #pp.full  <- seq(min(pr_val), max(pr_val), length = 100) #xxxx\n        pp.full<- seq(0.001, 0.99, length=100)\n        Sm.full  <- approx(Sm, xout = pp.full, ties = mean)$y #yyyyy\n        \n        \n        return(list(val_results = as.data.frame(val_results), cal_plot = list(sm = Sm.full)) )\n      }, error=function(e){\n        val_results[1,2] <- NA\n        val_results[1,3] <- NA\n        \n        Sm.full <- rep(NA, 100)\n        \n        return(list(val_results = as.data.frame(val_results), cal_plot = list(sm = Sm.full)) )\n      }\n      \n    )\n  }\n}\n\n# Define your own replacement function\nalpha <- function(col, alpha = 1) {\n  # Convert color to RGB and apply transparency\n  rgb.matrix <- grDevices::col2rgb(col, alpha = TRUE) / 255\n  grDevices::rgb(rgb.matrix[1,], rgb.matrix[2,], rgb.matrix[3,], alpha = alpha)\n}\n\n\ncalibrated_model_validation_results <- function(model, type, validation){\n  \n  val_results <- matrix(nrow = 1,ncol = 4)\n  colnames(val_results) <- c('AUC', 'CITL', 'CSLOPE', 'BrierScore') #'MER' = mean estimated risk\n  pr_val <- nrow(validation)\n  lp_val <- nrow(validation)\n  \n  validation$lp <- predict(model$source_model, newdata = validation, type = \"link\")\n  #print(table(validation$Y, validation$lp))\n  \n  if(type=='intercept_only'){\n    pr_val <- predict(model$calibrated_model, type=\"response\", newdata = validation, offset = validation$lp) # predict probabilities \n    lp_val <- predict(model$calibrated_model, newdata = validation, offset = validation$lp ) # predict lp type=link\n    #print(lp_val)\n  }else{\n    pr_val <- predict(model$calibrated_model, type=\"response\", newdata = validation, lp = validation$lp) # predict probabilities \n    lp_val <- predict(model$calibrated_model, newdata = validation, lp = validation$lp ) # predict lp type=link\n  }\n  \n  \n  # calculate performance of the  model in the validation sample\n  #val_cstat_model <- roc(Y ~ pr_val,data=validation)\n  #val_results[1,1] <- val_cstat_model$auc\n  \n  pred <- prediction(pr_val, validation$Y)\n  perf <- performance(pred, \"tpr\", \"fpr\")    \n  auc <- performance(pred, \"auc\")@y.values[[1]]\n  val_results[1,1] <- auc\n  \n  val_citl_model <- glm(Y ~ offset(lp_val),family=binomial, data=validation)\n  \n  \n  val_cslope_model <- glm(Y ~ lp_val,family=binomial(link='logit'), data=validation)\n  \n  \n  val_results[1,4] <- brier_score(validation$Y, pred=pr_val) #brier_score(model$calibrated_model)\n  \n  tryCatch(\n    {\n      val_results[1,2] <- summary(val_citl_model)$coefficients[1,1]\n      val_results[1,3] <- summary(val_cslope_model)$coefficients[2,1]\n      \n      Sm <- lowess(pr_val, validation$Y, iter = 0)\n      pp.full<- seq(0.001, 0.99, length=100)\n      Sm.full  <- approx(Sm, xout = pp.full, ties = mean)$y #yyyyy\n      return(list(val_results = as.data.frame(val_results), cal_plot = list(sm = Sm.full)) )\n      \n    }, error=function(e){\n      val_results[1,2] <- NA\n      val_results[1,3] <- NA\n      Sm.full <- rep(NA, 100)\n      return(list(val_results = as.data.frame(val_results), cal_plot = list(sm = Sm.full)) )\n    }\n  )\n}\n\n\nproposed_model_validation_results <- function(model, validation){\n  if(all(is.na(model))){\n    val_results <- matrix(nrow = 1,ncol = 4)\n    colnames(val_results) <- c('AUC', 'CITL', 'CSLOPE', 'BrierScore') #'MER' = mean estimated risk\n    \n    val_results[1,1] <- NA\n    val_results[1,2] <- NA\n    val_results[1,3] <- NA\n    val_results[1,4] <- NA\n    \n    Sm.full <- rep(NA, 100)\n    return(list(val_results = as.data.frame(val_results), cal_plot = list(sm = Sm.full)) )\n  }else{\n    val_results <- matrix(nrow = 1,ncol = 4)\n    colnames(val_results) <- c('AUC', 'CITL', 'CSLOPE', 'BrierScore') #'MER' = mean estimated risk\n    \n    \n    pr_val <- predict(model, type=\"response\", newdata = validation) # predict probabilities \n    lp_val <- predict(model, newdata = validation ) # predict lp type=link\n    \n    # print(pr_val[1:10])\n    # print(lp_val[1:10])\n    # calculate performance of the  model in the validation sample\n    #val_cstat_model <- roc(Y ~ pr_val,data=validation)\n    #val_results[1,1] <- val_cstat_model$auc\n    \n    pred <- prediction(pr_val, validation$Y)\n    perf <- performance(pred, \"tpr\", \"fpr\")    \n    auc <- performance(pred, \"auc\")@y.values[[1]]\n    val_results[1,1] <- auc\n    \n    val_results[1,4] <- brier_score(validation$Y, pred=pr_val)#brier_score(model)\n    \n    tryCatch(\n      { \n        val_citl_model <- glm(Y ~ offset(lp_val),family=binomial, data=validation)\n        val_results[1,2] <- summary(val_citl_model)$coefficients[1,1]\n        \n        val_cslope_model <- glm(Y ~ lp_val,family=binomial(link='logit'), data=validation)\n        val_results[1,3] <- summary(val_cslope_model)$coefficients[2,1]\n        \n        \n        Sm <- lowess(pr_val, validation$Y, iter = 0)\n        #pp.full  <- seq(min(pr_val), max(pr_val), length = 100) #xxxx\n        pp.full<- seq(0.001, 0.99, length=100)\n        Sm.full  <- approx(Sm, xout = pp.full, ties = mean)$y #yyyyy\n        \n        \n        return(list(val_results = as.data.frame(val_results), cal_plot = list(sm = Sm.full)) )\n      }, error=function(e){\n        val_results[1,2] <- NA\n        val_results[1,3] <- NA\n        \n        Sm.full <- rep(NA, 100)\n        \n        return(list(val_results = as.data.frame(val_results), cal_plot = list(sm = Sm.full)) )\n      }\n      \n    )\n  }\n}\n\n\n\nget_smoothed_mean <- function(pp_sm_list, sc_name){\n  smoothed_lines <- list()\n  \n  model_name <- pp_sm_list[[1]]['Model']\n  \n  for(i in 1:length(pp_sm_list)){\n    \n    Sm.full  <-  pp_sm_list[[i]]$sm[[1]]\n    \n    smoothed_lines[[i]] <- Sm.full\n  }\n  \n  \n  smoothed_matrix <- do.call(cbind, smoothed_lines)\n  smoothed_mean <- apply(smoothed_matrix, 1, median, na.rm = TRUE) #rowMeans(smoothed_matrix, na.rm = TRUE)\n  \n  return(list(smoothed_mean=smoothed_mean, model_name=model_name, sc_name=sc_name))\n}\n\n\nget_val_data <- function(model_df){\n  temp_df <- data.frame(AUC= get_ci(model_df$AUC), CITL=get_ci(model_df$CITL),\n                        CSLOPE=get_ci(model_df$CSLOPE), BrierScore=get_ci(model_df$BrierScore))\n  return(temp_df)\n}\n\nget_ci <- function(data){\n  #data <- sort(data)\n  #print(data)\n  data <- data[!is.na(data)]\n  \n  lower_band <- quantile(data, probs = 0.025, na.rm = TRUE)\n  upper_band <- quantile(data, probs = 0.975, na.rm = TRUE)\n  return(list(median = median(data), lower_band= lower_band, upper_band = upper_band, divergence = length(data)))\n}\n\n\n\nval_metric_plot <- function(df) { \n  df <- do.call(rbind, df)\n  df <- get_val_data(df)\n  \n  # Build a data frame with Metric, Estimate, and Divergence columns\n  summary_table <- tibble(\n    Metric = c(\"AUC\", \"Calibration-in-the-large\", \"Calibration slope\", \"Brier Score\"),\n    Estimate = c(\n      sprintf(\"%.3f (%.3f, %.3f)\", df$AUC.median, df$AUC.lower_band, df$AUC.upper_band),\n      sprintf(\"%.3f (%.3f, %.3f)\", df$CITL.median, df$CITL.lower_band, df$CITL.upper_band),\n      sprintf(\"%.3f (%.3f, %.3f)\", df$CSLOPE.median, df$CSLOPE.lower_band, df$CSLOPE.upper_band),\n      sprintf(\"%.3f (%.3f, %.3f)\", df$BrierScore.median, df$BrierScore.lower_band, df$BrierScore.upper_band)\n    ),\n    Divergence = c(\n      sprintf(\"%d/50 iterations\", df$AUC.divergence),\n      sprintf(\"%d/50 iterations\", df$CITL.divergence),\n      sprintf(\"%d/50 iterations\", df$CSLOPE.divergence),\n      sprintf(\"%d/50 iterations\", df$BrierScore.divergence)\n    )\n  ) %>%\n    mutate(Metric = paste0(\"<b>\", Metric, \"<\/b>\")) %>%\n    rename(`Estimate (95% CI)` = Estimate)\n  \n  return(summary_table)\n}\n\n\ncalibration_instability_plot<- function(pp_sm_list) {\n  smoothed_lines <- list()\n  plot(1, type = \"n\", xlim = c(0, 1), ylim = c(0, 1), xlab = \"Predicted\", ylab = \"Observed\")\n  \n  abline(a = 0, b = 1, col = 'black')  # Add ideal line\n  \n  pp.full <- seq(0.001, 0.99, length = 100)\n  for (i in 1:length(pp_sm_list)) {\n    Sm.full <- pp_sm_list[[i]]$sm\n    lines(pp.full, Sm.full, col = alpha('grey', 0.4))  # Add lines for single iteration\n    rug(Sm.full, side = 2, col = alpha('dark green', 0.4))  # Add rug plot on y-axis\n    smoothed_lines[[i]] <- Sm.full\n  }\n  \n  smoothed_matrix <- do.call(cbind, smoothed_lines)\n  smoothed_mean <- apply(smoothed_matrix, 1, median, na.rm = TRUE)\n  smoothed_quantiles <- apply(smoothed_matrix, 1, quantile, probs = c(0.025, 0.975), na.rm = TRUE)\n  \n  lines(pp.full, smoothed_mean, col = \"dark orange\", lwd = 1)  # Add median line\n  lines(pp.full, smoothed_quantiles[1, ], col = alpha(\"blue\", 0.8), lwd = 1, lty = \"dashed\")  # Add lower band\n  lines(pp.full, smoothed_quantiles[2, ], col = alpha(\"dark blue\", 0.8), lwd = 1, lty = \"dashed\")  # Add upper band\n  legend(\"bottomright\", legend = c(\"Ideal\", \"Single iteration\", \"Median\", \"Lower band\", \"Upper band\"),\n         col = c('black', alpha('grey', 0.4), \"dark orange\", alpha(\"blue\", 0.8), alpha(\"dark blue\", 0.8)),\n         lty = c(\"solid\", \"solid\", \"solid\", \"dashed\", \"dashed\"),  bty = \"n\")\n  \n}\n\n\n\n#bootstrap validation results\nCPM_validation_results <- function(model, validation){\n  if(all(is.na(model))){\n    val_results <- matrix(nrow = 1,ncol = 4)\n    colnames(val_results) <- c('AUC', 'CITL', 'CSLOPE', 'BrierScore') #'MER' = mean estimated risk\n    \n    val_results[1,1] <- NA\n    val_results[1,2] <- NA\n    val_results[1,3] <- NA\n    val_results[1,4] <- NA\n    \n    Sm.full <- rep(NA, 100)\n    return(list(val_results = as.data.frame(val_results), cal_plot = list(sm = Sm.full)) )\n  }else{\n    val_results <- matrix(nrow = 1,ncol = 4)\n    colnames(val_results) <- c('AUC', 'CITL', 'CSLOPE', 'BrierScore') #'MER' = mean estimated risk\n    \n    \n    pr_val <- predict(model, type=\"response\", newdata = validation) # predict probabilities \n    lp_val <- predict(model, type=\"link\", newdata = validation ) # predict lp type=link\n    \n    # print(pr_val[1:10])\n    # print(lp_val[1:10])\n    # calculate performance of the  model in the validation sample\n    #val_cstat_model <- roc(Y ~ pr_val,data=validation)\n    #val_results[1,1] <- val_cstat_model$auc\n    pred <- prediction(pr_val, validation$Y)\n    perf <- performance(pred, \"tpr\", \"fpr\")    \n    auc <- performance(pred, \"auc\")@y.values[[1]]\n    val_results[1,1] <- auc\n    \n    val_results[1,4] <- brier_score(validation$Y, pred=pr_val) \n    tryCatch(\n      { \n        val_citl_model <- glm(Y ~ offset(lp_val),family=binomial, data=validation)\n        val_results[1,2] <- summary(val_citl_model)$coefficients[1,1]\n        \n        val_cslope_model <- glm(Y ~ lp_val,family=binomial(link='logit'), data=validation)\n        val_results[1,3] <- summary(val_cslope_model)$coefficients[2,1]\n        \n        \n        Sm       <- lowess(pr_val, validation$Y, iter = 0)\n        #pp.full  <- seq(min(pr_val), max(pr_val), length = 100) #xxxx\n        pp.full<- seq(0.001, 0.99, length=100)\n        Sm.full  <- approx(Sm, xout = pp.full, ties = mean)$y #yyyyy\n        \n        \n        return(list(val_results = as.data.frame(val_results), cal_plot = list(sm = Sm.full)) )\n      }, error=function(e){\n        val_results[1,2] <- NA\n        val_results[1,3] <- NA\n        \n        Sm.full <- rep(NA, 100)\n        \n        return(list(val_results = as.data.frame(val_results), cal_plot = list(sm = Sm.full)) )\n      }\n      \n    )\n  }\n}\n\n\n\ncalibrated_model_validation_results <- function(model, type, validation){\n  \n  val_results <- matrix(nrow = 1,ncol = 4)\n  colnames(val_results) <- c('AUC', 'CITL', 'CSLOPE', 'BrierScore') #'MER' = mean estimated risk\n  pr_val <- nrow(validation)\n  lp_val <- nrow(validation)\n  \n  validation$lp <- predict(model$source_model, newdata = validation, type = \"link\")\n  #print(table(validation$Y, validation$lp))\n  \n  if(type=='intercept_only'){\n    pr_val <- predict(model$calibrated_model, type=\"response\", newdata = validation, offset = validation$lp) # predict probabilities \n    lp_val <- predict(model$calibrated_model, newdata = validation, offset = validation$lp ) # predict lp type=link\n    #print(lp_val)\n  }else{\n    pr_val <- predict(model$calibrated_model, type=\"response\", newdata = validation, lp = validation$lp) # predict probabilities \n    lp_val <- predict(model$calibrated_model, newdata = validation, lp = validation$lp ) # predict lp type=link\n  }\n  \n  \n  # calculate performance of the  model in the validation sample\n  #val_cstat_model <- roc(Y ~ pr_val,data=validation)\n  #val_results[1,1] <- val_cstat_model$auc\n  pred <- prediction(pr_val, validation$Y)\n  perf <- performance(pred, \"tpr\", \"fpr\")    \n  auc <- performance(pred, \"auc\")@y.values[[1]]\n  val_results[1,1] <- auc\n  \n  val_citl_model <- glm(Y ~ offset(lp_val),family=binomial, data=validation)\n  \n  \n  val_cslope_model <- glm(Y ~ lp_val,family=binomial(link='logit'), data=validation)\n  \n  \n  val_results[1,4] <- brier_score(validation$Y, pred=pr_val) #brier_score(model$calibrated_model)\n  \n  tryCatch(\n    {\n      val_results[1,2] <- summary(val_citl_model)$coefficients[1,1]\n      val_results[1,3] <- summary(val_cslope_model)$coefficients[2,1]\n      \n      Sm <- lowess(pr_val, validation$Y, iter = 0)\n      pp.full<- seq(0.001, 0.99, length=100)\n      Sm.full  <- approx(Sm, xout = pp.full, ties = mean)$y #yyyyy\n      return(list(val_results = as.data.frame(val_results), cal_plot = list(sm = Sm.full)) )\n      \n    }, error=function(e){\n      val_results[1,2] <- NA\n      val_results[1,3] <- NA\n      Sm.full <- rep(NA, 100)\n      return(list(val_results = as.data.frame(val_results), cal_plot = list(sm = Sm.full)) )\n    }\n  )\n}\n\n\nproposed_model_validation_results <- function(model, validation){\n  if(all(is.na(model))){\n    val_results <- matrix(nrow = 1,ncol = 4)\n    colnames(val_results) <- c('AUC', 'CITL', 'CSLOPE', 'BrierScore') #'MER' = mean estimated risk\n    \n    val_results[1,1] <- NA\n    val_results[1,2] <- NA\n    val_results[1,3] <- NA\n    val_results[1,4] <- NA\n    \n    Sm.full <- rep(NA, 100)\n    return(list(val_results = as.data.frame(val_results), cal_plot = list(sm = Sm.full)) )\n  }else{\n    val_results <- matrix(nrow = 1,ncol = 4)\n    colnames(val_results) <- c('AUC', 'CITL', 'CSLOPE', 'BrierScore') #'MER' = mean estimated risk\n    \n    \n    pr_val <- predict(model, type=\"response\", newdata = validation) # predict probabilities \n    lp_val <- predict(model, newdata = validation ) # predict lp type=link\n    \n    # print(pr_val[1:10])\n    # print(lp_val[1:10])\n    # calculate performance of the  model in the validation sample\n    #val_cstat_model <- roc(Y ~ pr_val,data=validation)\n    #val_results[1,1] <- val_cstat_model$auc\n    pred <- prediction(pr_val, validation$Y)\n    perf <- performance(pred, \"tpr\", \"fpr\")    \n    auc <- performance(pred, \"auc\")@y.values[[1]]\n    val_results[1,1] <- auc\n    \n    val_results[1,4] <- brier_score(validation$Y, pred=pr_val)#brier_score(model)\n    \n    tryCatch(\n      { \n        val_citl_model <- glm(Y ~ offset(lp_val),family=binomial, data=validation)\n        val_results[1,2] <- summary(val_citl_model)$coefficients[1,1]\n        \n        val_cslope_model <- glm(Y ~ lp_val,family=binomial(link='logit'), data=validation)\n        val_results[1,3] <- summary(val_cslope_model)$coefficients[2,1]\n        \n        \n        Sm <- lowess(pr_val, validation$Y, iter = 0)\n        #pp.full  <- seq(min(pr_val), max(pr_val), length = 100) #xxxx\n        pp.full<- seq(0.001, 0.99, length=100)\n        Sm.full  <- approx(Sm, xout = pp.full, ties = mean)$y #yyyyy\n        \n        \n        return(list(val_results = as.data.frame(val_results), cal_plot = list(sm = Sm.full)) )\n      }, error=function(e){\n        val_results[1,2] <- NA\n        val_results[1,3] <- NA\n        \n        Sm.full <- rep(NA, 100)\n        \n        return(list(val_results = as.data.frame(val_results), cal_plot = list(sm = Sm.full)) )\n      }\n      \n    )\n  }\n}\n\n\n\nget_smoothed_mean <- function(pp_sm_list, sc_name){\n  smoothed_lines <- list()\n  \n  model_name <- pp_sm_list[[1]]['Model']\n  \n  for(i in 1:length(pp_sm_list)){\n    \n    Sm.full  <-  pp_sm_list[[i]]$sm[[1]]\n    \n    smoothed_lines[[i]] <- Sm.full\n  }\n  \n  \n  smoothed_matrix <- do.call(cbind, smoothed_lines)\n  smoothed_mean <- apply(smoothed_matrix, 1, median, na.rm = TRUE) #rowMeans(smoothed_matrix, na.rm = TRUE)\n  \n  return(list(smoothed_mean=smoothed_mean, model_name=model_name, sc_name=sc_name))\n}\n\n\nget_val_data <- function(model_df){\n  temp_df <- data.frame(AUC= get_ci(model_df$AUC), CITL=get_ci(model_df$CITL),\n                        CSLOPE=get_ci(model_df$CSLOPE), BrierScore=get_ci(model_df$BrierScore))\n  return(temp_df)\n}\n\nget_ci <- function(data){\n  #data <- sort(data)\n  #print(data)\n  data <- data[!is.na(data)]\n  \n  lower_band <- quantile(data, probs = 0.025, na.rm = TRUE)\n  upper_band <- quantile(data, probs = 0.975, na.rm = TRUE)\n  return(list(median = median(data), lower_band= lower_band, upper_band = upper_band, divergence = length(data)))\n}\n\n\n\nval_metric_plot <- function(df) { \n  df <- do.call(rbind, df)\n  df <- get_val_data(df)\n  \n  # Build a data frame with Metric, Estimate, and Divergence columns\n  summary_table <- tibble(\n    Metric = c(\"AUC\", \"Calibration-in-the-large\", \"Calibration slope\", \"Brier Score\"),\n    Estimate = c(\n      sprintf(\"%.3f (%.3f, %.3f)\", df$AUC.median, df$AUC.lower_band, df$AUC.upper_band),\n      sprintf(\"%.3f (%.3f, %.3f)\", df$CITL.median, df$CITL.lower_band, df$CITL.upper_band),\n      sprintf(\"%.3f (%.3f, %.3f)\", df$CSLOPE.median, df$CSLOPE.lower_band, df$CSLOPE.upper_band),\n      sprintf(\"%.3f (%.3f, %.3f)\", df$BrierScore.median, df$BrierScore.lower_band, df$BrierScore.upper_band)\n    ),\n    Divergence = c(\n      sprintf(\"%d/50 iterations\", df$AUC.divergence),\n      sprintf(\"%d/50 iterations\", df$CITL.divergence),\n      sprintf(\"%d/50 iterations\", df$CSLOPE.divergence),\n      sprintf(\"%d/50 iterations\", df$BrierScore.divergence)\n    )\n  ) %>%\n    mutate(Metric = paste0(\"<b>\", Metric, \"<\/b>\")) %>%\n    rename(`Estimate (95% CI)` = Estimate)\n  \n  return(summary_table)\n}\n\n\ncalibration_instability_plot<- function(pp_sm_list) {\n  smoothed_lines <- list()\n  plot(1, type = \"n\", xlim = c(0, 1), ylim = c(0, 1), xlab = \"Predicted\", ylab = \"Observed\")\n  \n  abline(a = 0, b = 1, col = 'black')  # Add ideal line\n  \n  pp.full <- seq(0.001, 0.99, length = 100)\n  for (i in 1:length(pp_sm_list)) {\n    Sm.full <- pp_sm_list[[i]]$sm\n    lines(pp.full, Sm.full, col = alpha('grey', 0.4))  # Add lines for single iteration\n    rug(Sm.full, side = 2, col = alpha('dark green', 0.4))  # Add rug plot on y-axis\n    smoothed_lines[[i]] <- Sm.full\n  }\n  \n  smoothed_matrix <- do.call(cbind, smoothed_lines)\n  smoothed_mean <- apply(smoothed_matrix, 1, median, na.rm = TRUE)\n  smoothed_quantiles <- apply(smoothed_matrix, 1, quantile, probs = c(0.025, 0.975), na.rm = TRUE)\n  \n  lines(pp.full, smoothed_mean, col = \"dark orange\", lwd = 1)  # Add median line\n  lines(pp.full, smoothed_quantiles[1, ], col = alpha(\"blue\", 0.8), lwd = 1, lty = \"dashed\")  # Add lower band\n  lines(pp.full, smoothed_quantiles[2, ], col = alpha(\"dark blue\", 0.8), lwd = 1, lty = \"dashed\")  # Add upper band\n  legend(\"bottomright\", legend = c(\"Ideal\", \"Single iteration\", \"Median\", \"Lower band\", \"Upper band\"),\n         col = c('black', alpha('grey', 0.4), \"dark orange\", alpha(\"blue\", 0.8), alpha(\"dark blue\", 0.8)),\n         lty = c(\"solid\", \"solid\", \"solid\", \"dashed\", \"dashed\"),  bty = \"n\")\n  \n}\n\n\n# Calibration plot function\ncalibration_plot <- function(cal_plots) {\n  \n  calibration_instability_plot(cal_plots)\n}\n\nvalidation_results_table <- function(val_results){\n  val_metric_plot(val_results)\n  \n}\n\n\ncalibration_plot_noshift <- function(cal_plots_noshift) {\n  \n  calibration_instability_plot(cal_plots_noshift)\n}\n\nvalidation_results_table_noshift <- function(val_results_noshift){\n  val_metric_plot(val_results_noshift)\n  \n}\n\nui <- navbarPage(title = \"üî¨Heterogeneity Simulator\",\n                 \n                 # --- Info Tab ---\n                 tabPanel(\n                   \"‚ÑπÔ∏è About\",\n                   fluidPage(\n                     withMathJax(),\n                     tags$h2(\"Understanding Data Heterogeneity Impact on Model Performance\", style = \"margin-top: 20px; color: #2C3E50; font-weight: bold; text-align: center;\"),\n                     tags$h3(\"Simulating Distribution Shifts and Their Effects on Predictive Models\", style = \"margin-top: 20px; color: #2C3E50; font-weight: bold; text-align: center;\"),\n                     \n                     tags$hr(),\n                     tags$div(\n                       tags$ul(\n                         tags$li(HTML(\n                           \"This app provides an interactive simulation designed to explore the impact of heterogeneity within the development \n                           dataset on predictive model performance due to data distribution shifts, which occur when differences arise \n                            in the underlying distribution of the data. \n                                  <br> <br>\n                                  The development dataset in this simulation consists of two datasets:\n                                  <br>\n                           <br> 1) Target dataset is data sampled from a specific target population where the model is intended to be deployed. \n                           This dataset is generated using a set of fixed parameters. <br>\n                            <br> 2) Ancillary dataset is additional and potentially related data sampled from an ancillary population from a different time point or location. \n                           Users generate this dataset under different distribution shift scenarios, to simulate heterogeneity between the target and the ancillary datasets.<br>\"\n                         )),\n                         \n                         tags$h3(\"Distribution Shift Scenarios\")\n                         ,\n                         tags$li(\n                           HTML(\n                             \"Users can simulate the following main scenarios:\n              <br><strong>1. No data shift:<\/strong> Generate the ancillary population from same distribution as the target population.\n              <br><strong>2. Case-mix shift:<\/strong> Generate the ancillary population from a distribution that differs from the target\n              population by a shift in mean, variance, and/or event rate (prevalence) of any predictor.\n              <br><strong>3. Predictor-outcome association shift:<\/strong> Generate the ancillary population by shifting the coefficients\n              (Œ≤) of any predictor.\n              <br><strong>4. Event rate shift:<\/strong> Generate the ancillary population with a different intercept value.\n              <br><strong>5. Combination of shifts:<\/strong> Apply multiple shifts simultaneously to assess compounded effects.\"\n                           )\n                         ),\n                         tags$h3(\n                           HTML(\n                             \"Predictor-generation models\")\n                         ),\n                         \n                         tags$li(\n                           HTML(\n                             \"<strong>Predictor-generation model for the target population<\/strong> includes 5 variables:\n         <br>\n         \\\\[\n           X_{\\\\text{target}} = (X_1, X_2, X_3, X_4, X_5)^T \\\\sim MVN(\\\\mu_{\\\\text{target}}, \\\\Sigma_{\\\\text{target}})\n           \\\\]\n          <br>Where the mean vector \\\\(\\\\mu_{\\\\text{target}}\\\\) is set to 0, and the covariance matrix \\\\(\\\\Sigma_{\\\\text{target}}\\\\) is:\n          \n          <br><br>\n          <table border='1' cellpadding='5' cellspacing='0' style='border-collapse: collapse; text-align: center; margin: auto;'>\n          <tr>\n          <th><\/th><th>X‚ÇÅ<\/th><th>X‚ÇÇ<\/th><th>X‚ÇÉ<\/th><th>X‚ÇÑ<\/th><th>X‚ÇÖ<\/th>\n          <\/tr>\n          <tr><th>X‚ÇÅ<\/th><td>1<\/td><td>0.4<\/td><td>0.4<\/td><td>0<\/td><td>0.4<\/td><\/tr>\n          <tr><th>X‚ÇÇ<\/th><td>0.4<\/td><td>1<\/td><td>0.5<\/td><td>0<\/td><td>0.3<\/td><\/tr>\n          <tr><th>X‚ÇÉ<\/th><td>0.4<\/td><td>0.5<\/td><td>1<\/td><td>0<\/td><td>0.6<\/td><\/tr>\n          <tr><th>X‚ÇÑ<\/th><td>0<\/td><td>0<\/td><td>0<\/td><td>1<\/td><td>0.4<\/td><\/tr>\n          <tr><th>X‚ÇÖ<\/th><td>0.4<\/td><td>0.3<\/td><td>0.6<\/td><td>0.4<\/td><td>1<\/td><\/tr>\n          <\/table>\n          <br><br>\n          Predictors <code>X‚ÇÉ, X‚ÇÑ, X‚ÇÖ<\/code> are dichotomized using thresholds based on the variable‚Äôs distribution.\n          Values above the threshold are assigned 1, and those below 0, with prevalences:\n          <code>p‚ÇÉ = 0.3<\/code>, <code>p‚ÇÑ = 0.4<\/code>, <code>p‚ÇÖ = 0.1<\/code>.<br> <br>\"\n                           )\n                         ),\n                         \n                         tags$li(\n                           HTML(\n                             \"<strong>Predictor-generation model for the ancillary population<\/strong>:\n                  <br>\n         \\\\[\n           X_{\\\\text{ancillary}} = MVN(\\\\mu_{\\\\text{target}}+ \\\\Delta_{\\\\mu}, \\\\Sigma_{\\\\text{target}} +  \\\\Delta_{\\\\Sigma})\n           \\\\] <br>      <br> where \\\\( \\\\Delta \\\\) refers to the user-specified shift.\"\n                           )\n                         ),\n                         \n                         tags$h3(\n                           HTML(\n                             \"Outcome-generation models\")\n                         ),\n                         \n                         tags$li(\n                           HTML(\n                             \"The following <strong>outcome-generation model for the target population<\/strong> is uded to generate a binary outcome {Y}:\n                   <br>\n                   \\\\[\n                   P(Y = 1 \\\\mid X) = \\\\pi_{\\\\text{target}} = \\\\left[1 + \\\\exp\\\\left( - \\\\left( \\\\beta_{0,\\\\text{target}} + \\\\sum_{k=1}^{5} \\\\beta_{k,\\\\text{target}} X_k \\\\right) \\\\right) \\\\right]^{-1}\n                   \\\\]\n                   <br>\n                   With coefficients:\n                   <code>Œ≤‚ÇÄ = -3.1, Œ≤‚ÇÅ = 0.5, Œ≤‚ÇÇ = 0.3, Œ≤‚ÇÉ = 0.7, Œ≤‚ÇÑ = 0.8, Œ≤‚ÇÖ = 0.2<\/code>  <br>  <br>\"\n                           )\n                         ),\n                         \n                         tags$li(\n                           HTML(\n                             \"<strong>The outcome-generation model for the ancillary population<\/strong>:\n               <br>\n               \\\\[\n               P(Y = 1 \\\\mid X) = \\\\pi_{\\\\text{ancillary}} =\n               \\\\left[ 1 + \\\\exp\\\\left( - \\\\left( (\\\\beta_{0,\\\\text{target}} + \\\\Delta\\\\beta_{0}) +\n               \\\\sum_{k=1}^{5} (\\\\beta_{k,\\\\text{target}} + \\\\Delta\\\\beta_{k}) X_k \\\\right) \\\\right) \\\\right]^{-1}\n               \\\\]\n               <br>      <br> where \\\\( \\\\Delta \\\\) refers to the user-specified shift. <br> <br>\n              \"\n                           )\n                         ) ,\n                         tags$li(\"Throughout all the simulation iterations across all simulation scenarios, a large population-level datasets is going to be generated‚Äîcomprising a total of 100,000 observations‚Äî for both the target and ancillary populations. \n                                 The goal is to simulate overarching populations from which users can draw random samples for developing the model.\"\n                         ),\n                         tags$h3(\"Development dataset\"),\n                         tags$li(\n                           \"Users can draw the development dataset using combination of the target and ancillary populations subsets,\n                            with varying proportions of splits.\"\n                         ), \n                         tags$h3(\"Validation dataset\"),\n                         tags$li(\"The model performance is evaluated on a large validation dataset (10,000), \n                                 drawn from the same data-generating mechanism as the target population.\"\n                         ) ,\n                         tags$li(\"Each simulation run performs 50 iterations.\"),\n                         tags$h3(\"Survey\", style = \"color: darkred;\"),\n                         tags$li(\"After exploring the app, please participate in this survey\", style = \"color: darkred;\", \n                                 tags$a(href=\"https://tinyurl.com/uomappsurvey\", \"https://tinyurl.com/uomappsurvey.\") ,tags$br(),\n                                 \"The purpose of this survey is to gather your feedback on the app. \n                           Your participation will help us understand how effective the tool is for learning, how engaging and easy to use it is,\n                                and how it could be improved.\", style = \"color: darkred;\" ),\n                         tags$br(),\n                         \n                         p(\" ¬© 2025 Haya Elayan. All rights reserved.\")\n                       ),\n                       style = \"font-size: 15px; max-width: 800px; margin: auto;\"\n                     )\n                     \n                   )\n                 ),\n                 # --- Simulation Tab ---\n                 tabPanel(\n                   \"üìä Simulation\",\n                   fluidPage(\n                     useShinyjs(),\n                     #theme = shinytheme(\"darkly\"), \n                     tags$head(\n                       # Load FontAwesome for icon\n                       tags$link(\n                         rel = \"stylesheet\",\n                         href = \"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css\"\n                       ),\n                       # Initialize Bootstrap 3 tooltips on document ready and Shiny updates\n                       tags$script(HTML(\"\n          $(document).on('shiny:connected shiny:inputchanged shiny:value', function() {\n            $('[data-toggle=\\\"tooltip\\\"]').tooltip();\n          });\n        \"))\n                     ),\n                     tags$div(\n                       tags$h2(\"Simulate and Analyze Data\",\n                               style = \"color: #2C3E50; font-weight: bold; text-align: left; margin-top: 20px;\")\n                     ),\n                     tags$div(\n                       tags$h4(\n                         \"Adjust simulation parameters and visualize model behavior.\",\n                         style = \"color: #7F8C8D; text-align: left; margin-bottom: 20px;\"\n                       )\n                     ),\n                     titlePanel(\"Simulation Parameters\"),\n                     sidebarLayout(\n                       sidebarPanel(\n                         tags$label(\n                           HTML(\"Development dataset sample size\"),\n                           tags$i(\n                             class = \"fas fa-info-circle\",\n                             style = \"margin-left: 5px; color: #007BFF; cursor: pointer;\",\n                             `data-toggle` = \"tooltip\",\n                             title = \"Development dataset =  Ancillary dataset + Target dataset\"\n                           )\n                         ),\n                         div( style = \"margin-bottom: 20px\",\n                              sliderInput(\n                                \"N_SAMPLES\", NULL, min = 500, max = 9500, value = 1000,  step = 500\n                              )),\n                         \n                         tags$label(\n                           HTML(\"\n                            Proportion split of the development dataset:<br>\n                            <b>Target dataset proportion<\/b>\"),\n                           tags$i(\n                             class = \"fas fa-info-circle\",\n                             style = \"margin-left: 5px; color: #007BFF; cursor: pointer;\",\n                             `data-toggle` = \"tooltip\",\n                             title = \"This is the proportion of the data allocated to the target dataset. The rest goes to the ancillary dataset = 1 - (Target dataset proportion).\"\n                           )\n                         ),\n                         div(style = \"margin-bottom: 20px\", sliderInput(\"target_split\", NULL, min = 0.1, max = 0.9, value = 0.5, step = 0.01)),\n                         tags$label(\n                           HTML(\"Model development method:\"),\n                           tags$i(\n                             class = \"fas fa-info-circle\",\n                             style = \"margin-left: 5px; color: #007BFF; cursor: pointer;\",\n                             `data-toggle` = \"tooltip\",\n                             title = \"See 'Methods' tab above for more information about each method.\"\n                           )\n                         ),\n                         selectInput(\n                           \"cpm_method\",\n                           NULL,\n                           choices = c(\"Full-data Logistic Regression\",\"Target-dataset only logistic regression\",\n                                       \"Ancillary-dataset only logistic regression\", \"Memebership-based Weighting\",\n                                       \"Intercept Recalibration on all data\", \"Logistic Recalibration on all data\")\n                         )\n                         ,\n                         tags$label(\n                           HTML(\"Predictors:\")),\n                         \n                         tags$head(\n                           tags$style(HTML(\"\n      .panel-title > a:after {\n        content: '\\\\25B6'; /* ‚ñ∂ right arrow */\n        float: right;\n        margin-right: 10px;\n        transition: transform 0.3s ease;\n      }\n\n      .panel-title > a[aria-expanded='true']:after {\n        content: '\\\\25BC'; /* ‚ñº down arrow */\n      }\n    \"))\n                         ),\n                         bsCollapsePanel(HTML(\"<strong>Intercept<\/strong>\"),\n                                         sliderInput( \"X0_b_delta\", \"Intercept Shift\",  min = -3, max = 3, value = 0,  step = 0.1 )),\n                         \n                         tags$head(\n                           tags$style(HTML(\"\n      .panel-title > a:after {\n        content: '\\\\25B6'; /* ‚ñ∂ right arrow */\n        float: right;\n        margin-right: 10px;\n        transition: transform 0.3s ease;\n      }\n\n      .panel-title > a[aria-expanded='true']:after {\n        content: '\\\\25BC'; /* ‚ñº down arrow */\n      }\n    \")) ),\n                         bsCollapsePanel(HTML(\"<strong>X1 (Continuous)<\/strong>\"),\n                                         sliderInput(\"X1_m_delta\", \"X1 Mean Shift\", min = -10, max = 10, value = 0, step = 0.1),\n                                         sliderInput(\"X1_v_delta\", \"X1 Variance Shift\", min = -10, max = 10, value = 0, step = 0.1),\n                                         sliderInput(\"X1_b_delta\", \"X1 Beta Shift\", min = -3, max = 3, value = 0, step = 0.1)\n                         )\n                         \n                         \n                         ,\n                         tags$head(\n                           tags$style(HTML(\"\n      .panel-title > a:after {\n        content: '\\\\25B6'; /* ‚ñ∂ right arrow */\n        float: right;\n        margin-right: 10px;\n        transition: transform 0.3s ease;\n      }\n\n      .panel-title > a[aria-expanded='true']:after {\n        content: '\\\\25BC'; /* ‚ñº down arrow */\n      }\n    \"))),\n                         bsCollapsePanel(HTML(\"<strong>X2 (Continuous)<\/strong>\"),\n                                         sliderInput(\n                                           \"X2_m_delta\",  \"X2 Mean Shift\", min = -10, max = 10,   value = 0, step = 0.1  ),\n                                         sliderInput(\n                                           \"X2_v_delta\",   \"X2 Variance Shift\",  min = -10,    max = 10,    value = 0,  step = 0.1 ),\n                                         sliderInput(\n                                           \"X2_b_delta\", \"X2 Beta Shift\", min = -3, max = 3, value = 0, step = 0.1 )\n                         ),\n                         \n                         \n                         tags$head(\n                           tags$style(HTML(\"\n      .panel-title > a:after {\n        content: '\\\\25B6'; /* ‚ñ∂ right arrow */\n        float: right;\n        margin-right: 10px;\n        transition: transform 0.3s ease;\n      }\n\n      .panel-title > a[aria-expanded='true']:after {\n        content: '\\\\25BC'; /* ‚ñº down arrow */\n      }\n    \"))),\n                         bsCollapsePanel(HTML(\"<strong>X3 (Binary)<\/strong>\"),\n                                         sliderInput(\n                                           \"X3_p_delta\", \"X3 Prevalence Shift\",  min = -0.3,  max = 0.7, value = 0, step = 0.1),\n                                         sliderInput(   \"X3_b_delta\", \"X3 Beta Shift\", min = -3, max = 3, value = 0,  step = 0.1)\n                         ),\n                         \n                         tags$head(\n                           tags$style(HTML(\"\n      .panel-title > a:after {\n        content: '\\\\25B6'; /* ‚ñ∂ right arrow */\n        float: right;\n        margin-right: 10px;\n        transition: transform 0.3s ease;\n      }\n\n      .panel-title > a[aria-expanded='true']:after {\n        content: '\\\\25BC'; /* ‚ñº down arrow */\n      }\n    \"))),\n                         bsCollapsePanel(HTML(\"<strong>X4 (Binary)<\/strong>\"),\n                                         sliderInput(\n                                           \"X4_p_delta\", \"X4 Prevalence Shift\", min = -0.4, max = 0.6, value = 0,  step = 0.1\n                                         ),\n                                         sliderInput(\n                                           \"X4_b_delta\", \"X4 Beta Shift\", min = -3, max = 3, value = 0, step = 0.1\n                                         )\n                         ),\n                         \n                         tags$head(\n                           tags$style(HTML(\"\n      .panel-title > a:after {\n        content: '\\\\25B6'; /* ‚ñ∂ right arrow */\n        float: right;\n        margin-right: 10px;\n        transition: transform 0.3s ease;\n      }\n\n      .panel-title > a[aria-expanded='true']:after {\n        content: '\\\\25BC'; /* ‚ñº down arrow */\n      }\n    \"))),\n                         bsCollapsePanel(HTML(\"<strong>X5 (Binary)<\/strong>\"),\n                                         sliderInput(\"X5_p_delta\", \"X5 Prevalence Shift\", min = -0.1, max = 0.9,  value = 0, step = 0.1\n                                         ),\n                                         sliderInput(\n                                           \"X5_b_delta\", \"X5 Beta Shift\",  min = -3, max = 3, value = 0, step = 0.1)\n                         ),\n                         \n                         div(\n                           style = \"display: flex; flex-wrap: wrap\",  # gap adds space between buttons\n                           \n                           actionButton(\"simulate\", \"Simulate Data\", style = \"margin-bottom: 20px; margin-top: 20px; margin-right:10px\"),\n                           actionButton(\"reset\", \"Reset Inputs\", icon = icon(\"undo\"), style = \"margin-bottom: 20px; margin-top: 20px\")\n                         ),\n                         \n                         hidden(div(\n                           id = \"sim-spinner\",\n                           tags$h5(\"Running Simulation...\"),\n                           tags$i(class = \"fas fa-hourglass-half fa-spin fa-2x\")\n                         ))\n                       ),\n                       \n                       mainPanel(\n                         waiter::use_waiter(),\n                         conditionalPanel(\n                           condition = \"output.plotReady == true\",\n                           \n                           # No Shift Section\n                           tags$label(\n                             h3(span(\"No Data Shift Scenario\", style = \"color: #2E8B57; font-weight: bold;\"),\n                                tags$i(\n                                  class = \"fas fa-info-circle\",\n                                  style = \"margin-left: 5px; color: #007BFF; cursor: pointer;\",\n                                  `data-toggle` = \"tooltip\",\n                                  title = \"The ancillary population is generated from same distribution as the target population\"\n                                ))\n                           ),\n                           \n                           div(\n                             style = \"display: flex; align-items: flex-start; gap: 20px; margin-bottom: 40px;\",\n                             div(\n                               id = \"table-container_noshift\",\n                               style = \"width: 54%; min-height: 300px; margin: 0; padding: 0;\",\n                               tableOutput(\"results_summary_noshift\")\n                             ),\n                             div(\n                               id = \"calPlot-container_noshift\",\n                               style = \"width: 49%; margin-top: -80px; padding: 0;\",\n                               plotOutput(\"calPlot_noshift\", height = \"370px\")\n                             )\n                           ),\n                           \n                           # Shift Section\n                           h3(span(\"Selected Scenario\", style = \"color: #0072B2; font-weight: bold;\")),\n                           div(\n                             style = \"display: flex; align-items: flex-start; gap: 20px;\",\n                             div(\n                               id = \"table-container\",\n                               style = \"width: 54%; min-height: 300px; margin: 0; padding: 0;\",\n                               tableOutput(\"results_summary\")\n                             ),\n                             div(\n                               id = \"calPlot-container\",\n                               style = \"width: 49%; margin-top: -80px; padding: 0;\",\n                               plotOutput(\"calPlot\", height = \"370px\")\n                             )\n                           )\n                         )\n                       )\n                     )\n                   )\n                 ),\n                 tabPanel(\n                   \"üõ†Ô∏è Methods\",\n                   fluidPage(\n                     withMathJax(),\n                     \n                     h4(\"This simulation focuses on logistic regression-based models to estimate the probability of the binary outcome \\\\(Y\\\\).\"),\n                     tags$li(HTML(\"<strong>Develop model on full data<\/strong>: <br>This method uses the standard unweighted logistic regression to develop a model on both target and ancillary data. <br> <br><br>\")),\n                     tags$li(HTML(\"<strong>Develop model on target only<\/strong>: <br>This method uses the standard unweighted logistic regression to develop a model on the target data only. <br> <br><br>\")),\n                     tags$li(HTML(\"<strong>Develop model on ancillary only<\/strong>: <br>This method uses the standard unweighted logistic regression to develop a model on the ancillary data only. <br> <br><br>\")),\n                     \n                     tags$li(\n                       HTML(\n                         \"<strong>Model Re-calibration: Updating the intercept only<\/strong>: <br> \n                         One of discrete model updating methods that uses the new available data to update the model is Re-calibration by updating the intercept only, which intends to correct ‚Äúcalibration-in-the-large‚Äù, \n                         i.e make the average predicted probability equal to the observed overall event rate. This method is implemented by develop the model on all data and update on target only,\n                         a logistic regression model is developed on both ancillary and target (full development dataset), referred as `full model', then the the linear predictor \n                         of the `full model' is updated  on target only to obtain \\\\(LP_\\\\text{target}\\\\). Next, a logistic regression \n                         is fit on the target with fixing \\\\(LP_\\\\text{target}\\\\) as offset variable (the regression coefficient is constrained to be 1).<br> <br><br>\"\n                       )\n                     ),\n                     tags$li(\n                       HTML(\n                         \"<strong>Model Re-calibration: Logistic calibration<\/strong>: <br> \n                         Another method of discrete model updating that uses the new available data to update the model is Re-calibration by Logistic Calibration, which intends to correct both the intercept and the overall calibration slope. \n                         This method is implemented by developing the model on all data and update on target only,\n                         a logistic regression model is developed on both ancillary and target (full development dataset), referred as `full model', then the the linear predictor \n                         of the `full model' is updated  on target only to obtain \\\\(LP_\\\\text{target}\\\\). Next, a logistic regression \n                         is fit on the target with setting \\\\(LP_\\\\text{target}\\\\) as the only variable.<br> <br><br>\"\n                       )\n                       \n                     ),\n                     tags$li(\n                       HTML(\n                         \"<strong>Membership-based recalibration method: Develop on ancillary and target<\/strong><br>\n                      This method aims to develop a weighted model by giving individuals from the ancillary data high\n                      weights when they are relevant to target and low weights when they are less relevant to target. \n                      The weights are defined based on the relatedness of the individual samples from the ancillary\n                      data compared with the target data using a probabilistic similarity metric called the \n                      'membership model' that is based on the propensity score, thus adjusting the distribution of \n                      the ancillary data to correct for distributional changes.<br>\n                      <br>\n                      First, the membership propensity score \\\\(PS\\\\) is utilized, which is defined as the conditional probability \n                      of a randomly chosen individual in the study population belonging to the ancillary group, \n                      given their observed values from a set of predictor variables \n                      \\\\(\\\\boldsymbol{X}_i = (X_{i1}, \\\\ldots, X_{iK})\\\\), where \\\\(K\\\\) denotes \n                      the number of measured predictor variables, such that:\n                      <br><br>\n                      \\\\[\n                      PS_i = P(R = 1 \\\\mid \\\\mathbf{X}_i), \\\\quad \\\\text{for } i \\\\in \\\\{1, \\\\ldots, N_{\\\\text{ancillary}}\\\\}\n                      \\\\]\n                      <br>\n                      \n                      <br>\n                      A binary logistic regression model (membership model) is used to estimate \\\\(PS\\\\), where the outcome of the membership model is 0 for \n                      individuals of target and 1 for individuals of ancillary. \n                      Then, a weight \\\\(w_i\\\\) is produced for an individual \\\\(i\\\\) from ancillary dataset by dividing the Membership\n                      propensity score of target by the Membership propensity score of ancillary. \n                      To account for differences in sample sizes between the target and ancillary datasets, \n                      the weight is adjusted by multiplying it by the ratio of sample sizes (i.e., the sample size of the ancillary dataset divided by the sample size of the \n                      target dataset). This adjustment ensures that each dataset contributes proportionally to the final weights, \n                      reflecting the relative sizes of the datasets. The weight is calculated as follows: \n                      \\\\[\n                        w_i = \\\\min\\\\left( \n                        \\\\left( \\\\frac{P(R = 0 \\\\mid \\\\mathbf{X}_i)}{P(R = 1 \\\\mid \\\\mathbf{X}_i)} \n                        \\\\times \\\\frac{N_{\\\\text{ancillary}}}{N_{\\\\text{target}}} \\\\right),\\\\ 1 \n                        \\\\right) \\\\times \\\\lambda\n                        \\\\]\n                                          \n                      where \\\\(\\\\lambda\\\\) is an overall `forgetting factor' to further down-weight the ancillary, estimated as a hyperparameter using \n                      4-fold cross-validation. Adding \\\\(\\\\lambda\\\\) is crucial to correct for predictor-outcome association shift, if any, as\n                      the Membership propensity score only correct for case-mix shift.  \n                      After that, a weighted regression model is used with \\\\(K\\\\) set of predictors to weight each individual from ancillary in the \n                      log likelihood based on their relatedness to target, while weighting individuals from target with weight equal to 1. \n                      Let individual \\\\(i\\\\) and \\\\(w_i\\\\) is the corresponding individual weight from weights set that was calculated based on the\n                      importance of each individual. \n                      The weights are then included in the log-likelihood \\\\(LL\\\\) of the model as follows:\n                      \\\\[\n                        \\\\text{LL} = \\\\sum_{i=1}^{N} \\\\left(Y_i \\\\times \\\\log(P_i) + (1 - Y_i) \\\\times \\\\log(1 - P_i)\\\\right) \\\\times w_i\n                        \\\\]\n                        where \\\\(P\\\\) is the predicted probability for a binary outcome. \n                      <br>\n                      <br>This method  is implemented by Recalibration, where \\\\(PS\\\\) is estimateed in the weighting scheme given the observed values from \n                      a set of predictor variables \\\\(\\\\boldsymbol{X}_i = (X_{i1}, \\\\ldots, X_{iK})\\\\) only. Then after developing the weighted model, \n                      the calibration in the large (CITL) of the weighted model is adjustedthrough adding a dummy variable \n                      for the target membership \\\\(R\\\\). The dummy variable \\\\(R\\\\) indicates the absence or presence \n                      of the effect of target membership that causes a shift for the outcome, where it takes a value of 0 if the samples\n                      belong to target, and a value of 1 if the samples belong to ancillary. The dummy variable is added as an additional\n                      predictor in the developed model. \n                      <br>\n                      Note: This method reuqire longer time to run compared to other methods due to the cross-validation process.\n                      \"\n                       )\n                     )\n                   )\n                 )\n                 \n)\n\n\nserver <- function(input, output, session) {\n  sim_data <- reactiveVal()\n  noshift_data <- reactiveVal()\n  hide(\"sim-spinner\")\n  \n  output$plotReady <- reactive({\n    !is.null(sim_data()) && !is.null(noshift_data())\n  })\n  outputOptions(output, \"plotReady\", suspendWhenHidden = FALSE)\n  error_notification_id <- NULL\n  \n  observeEvent(input$simulate, {\n    sim_data(NULL)\n    noshift_data(NULL)\n    \n    if (!is.null(error_notification_id)) {\n      removeNotification(error_notification_id)\n      error_notification_id <<- NULL\n    }\n    \n    # Capture inputs outside the future (good!)\n    N_SAMPLES <- input$N_SAMPLES\n    target_split <- input$target_split\n    X0_b_delta <- input$X0_b_delta\n    X1_m_delta <- input$X1_m_delta\n    X1_v_delta <- input$X1_v_delta\n    X1_b_delta <- input$X1_b_delta\n    X2_m_delta <- input$X2_m_delta\n    X2_v_delta <- input$X2_v_delta\n    X2_b_delta <- input$X2_b_delta\n    X3_p_delta <- input$X3_p_delta\n    X3_b_delta <- input$X3_b_delta\n    X4_p_delta <- input$X4_p_delta\n    X4_b_delta <- input$X4_b_delta\n    X5_p_delta <- input$X5_p_delta\n    X5_b_delta <- input$X5_b_delta\n    cpm_method <- input$cpm_method\n    \n    show(\"sim-spinner\")\n    \n    # --- FUTURE 1: simulate_data ---\n    fut1 <- future({\n      \n      message(Sys.time(), \": Starting simulate_data\")\n      \n      result <- simulate_data(\n        N_SAMPLES = N_SAMPLES,\n        target_split = target_split,\n        X0_b_delta = X0_b_delta,\n        X1_m_delta = X1_m_delta,\n        X1_v_delta = X1_v_delta,\n        X1_b_delta = X1_b_delta,\n        X2_m_delta = X2_m_delta,\n        X2_v_delta = X2_v_delta,\n        X2_b_delta = X2_b_delta,\n        X3_p_delta = X3_p_delta,\n        X3_b_delta = X3_b_delta,\n        X4_p_delta = X4_p_delta,\n        X4_b_delta = X4_b_delta,\n        X5_p_delta = X5_p_delta,\n        X5_b_delta = X5_b_delta,\n        cpm_method = cpm_method\n      )\n      \n      message(Sys.time(), \": Finished simulate_data\")\n      result\n    }, seed = TRUE , packages = c(\"tidyr\", \"promises\", \"Matrix\"))\n    \n    # --- FUTURE 2: simulate_noshift ---\n    fut2 <- future({\n      \n      message(Sys.time(), \": Starting simulate_noshift\")\n      \n      result <- simulate_noshift(\n        N_SAMPLES = N_SAMPLES,\n        target_split = target_split,\n        cpm_method = cpm_method\n      )\n      \n      message(Sys.time(), \": Finished simulate_noshift\")\n      result\n    }, seed = TRUE, packages = c(\"tidyr\", \"promises\", \"Matrix\"))\n    \n    # --- Handle both futures ---\n    promise_all(fut1 = fut1, fut2 = fut2) %...>% (function(results) {\n      sim_data(results$fut1)\n      noshift_data(results$fut2)\n      \n      hide(\"sim-spinner\")\n      enable(\"simulate\")\n      \n      # Remove any old error message if present\n      if (!is.null(error_notification_id)) {\n        removeNotification(error_notification_id)\n        error_notification_id <<- NULL\n      }\n      \n    }) %...!% (function(e) {\n      print(e)\n\n      hide(\"sim-spinner\")\n      enable(\"simulate\")\n      \n      # Remove any old notification first\n      if (!is.null(error_notification_id)) {\n        removeNotification(error_notification_id)\n      }\n      \n      # Show a persistent error message\n      id <- showNotification(\n        \"‚ö†Ô∏è Failed to compute covariance matrix. Please choose different values for shifts.\",\n        #e$message,\n        type = \"error\",\n        duration = NULL  # persistent until removed\n      )\n      \n      error_notification_id <<- id\n    })\n  })\n  \n  \n  observeEvent(input$reset, {\n    # (unchanged)\n    updateNumericInput(session, \"N_SAMPLES\", value = 1000)\n    updateSliderInput(session, \"target_split\", value = 0.5)\n    updateSliderInput(session, \"X0_b_delta\", value = 0)\n    updateSliderInput(session, \"X1_m_delta\", value = 0)\n    updateSliderInput(session, \"X1_v_delta\", value = 0)\n    updateSliderInput(session, \"X1_b_delta\", value = 0)\n    updateSliderInput(session, \"X2_m_delta\", value = 0)\n    updateSliderInput(session, \"X2_v_delta\", value = 0)\n    updateSliderInput(session, \"X2_b_delta\", value = 0)\n    updateSliderInput(session, \"X3_p_delta\", value = 0)\n    updateSliderInput(session, \"X3_b_delta\", value = 0)\n    updateSliderInput(session, \"X4_p_delta\", value = 0)\n    updateSliderInput(session, \"X4_b_delta\", value = 0)\n    updateSliderInput(session, \"X5_p_delta\", value = 0)\n    updateSliderInput(session, \"X5_b_delta\", value = 0)\n    updateSelectInput(session, \"cpm_method\", selected = \"Full-data Logistic Regression\")\n    \n    # Also clear any existing error notification\n    if (!is.null(error_notification_id)) {\n      removeNotification(error_notification_id)\n      error_notification_id <<- NULL\n    }\n  })\n  \n  # --- Outputs ---\n  output$calPlot <- renderPlot({\n    req(sim_data())\n    calibration_plot(sim_data()$cal_plots)\n  })\n  \n  output$results_summary <- renderTable({\n    req(sim_data())\n    validation_results_table(sim_data()$val_results)\n  }, sanitize.text.function = function(x) x)\n  \n  output$calPlot_noshift <- renderPlot({\n    req(noshift_data())\n    calibration_plot_noshift(noshift_data()$cal_plots_noshift)\n  })\n  \n  output$results_summary_noshift <- renderTable({\n    req(noshift_data())\n    validation_results_table_noshift(noshift_data()$val_results_noshift)\n  }, sanitize.text.function = function(x) x)\n}\n\n\n\n# Run the app\nshinyApp(ui = ui, server = server)\n","type":"text"},{"name":"DatasetShift Simulation.Rproj","content":"Version: 1.0\n\nRestoreWorkspace: Default\nSaveWorkspace: Default\nAlwaysSaveHistory: Default\n\nEnableCodeIndexing: Yes\nUseSpacesForTab: Yes\nNumSpacesForTab: 2\nEncoding: UTF-8\n\nRnwWeave: Sweave\nLaTeX: pdfLaTeX\n","type":"text"}]
